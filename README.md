# proxy-pool
- crwaler：负责抓取代理并返回。
  - 因为不同的代理网站的网页结构不同，所以需要单独为每一个代理网页写爬虫。
  - 调用每个爬取方法，依次返回结果。　　
- db：负责代理的存取与代理分数的设置。
  - 判断待存入代理是否存在，不存在便存入数据库。
  - 将代理存入数据库，首次入库的代理分数设置为100。
  - 代理测试失败时，代理分数做相应的扣除，分数低于指定值时从数据库中移除。代理测试成功时，将代理分数重新设置为100。
  - 需要使用代理时，从数据库中随机取出高分代理。
- saver：负责执行爬取，并将结果存入数据库。
  - 判断数据库是否已经达到满足值，根据返回值决定是否执行爬取。
  - 将爬取得到的结果存入数据库
- tester：负责测试代理对目标网站的可用性。
  - 用每一个代理爬取目标网站，根据响应状态码对代理分数进行设置。
- api：负责提供获取代理信息的接口。
- run：复制控制是否抓取代理, 是否测试代理, 是否打开代理获取接口
- settings：设置信息。
这里我只爬取了两个代理网站的代理，西刺和快代理，可以在 Crawler 类中添加名称以 crwal_ 开始的方法来扩充。
